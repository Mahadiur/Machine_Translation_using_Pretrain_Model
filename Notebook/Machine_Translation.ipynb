{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": "### **Machine Translation using Pretrain Model**",
   "id": "8ba0d0d2b0b3fcb8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T14:08:52.226974Z",
     "start_time": "2025-10-27T14:08:52.224513Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pytorch_lightning.utilities.types import EVAL_DATALOADERS\n",
    "\n",
    "''' Import all important Library '''\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import pytorch_lightning\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch.nn as nn\n",
    "from torchmetrics.text import  BLEUScore"
   ],
   "id": "1ebf8cc152cc8749",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T14:08:52.236664Z",
     "start_time": "2025-10-27T14:08:52.234445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "''' Root and Dataset Path '''\n",
    "Root_dir = '/Users/mahadiur/Desktop/Bongodev MLops Projects/Machine Translation using Pretrain Model/Data'\n",
    "\n",
    "train_path = os.path.join(Root_dir, 'train.csv')\n",
    "test_path = os.path.join(Root_dir, 'test.csv')\n",
    "validation_path = os.path.join(Root_dir, 'val.csv')\n"
   ],
   "id": "ff3d084dfdf4301e",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T14:08:52.311500Z",
     "start_time": "2025-10-27T14:08:52.243562Z"
    }
   },
   "cell_type": "code",
   "source": [
    "''' Load Dataset '''\n",
    "train_dataset = pd.read_csv(train_path)\n",
    "test_dataset = pd.read_csv(test_path)\n",
    "validation_dataset = pd.read_csv(validation_path)\n",
    "\n",
    "train_dataset.head()"
   ],
   "id": "aafc870bdd777f38",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                  en  \\\n",
       "0       men with orange wristbands perform a dance .   \n",
       "1   a man with a grey beard is sitting by a window .   \n",
       "2     a dog walking through the water at the ocean .   \n",
       "3  a bike racer in a red jersey is pursued by ano...   \n",
       "4  two identical dogs bound across a lush green m...   \n",
       "\n",
       "                                                 bn  \n",
       "0                কমলা রিস্টব্যান্ড পড়া লোক নাচছে ।  \n",
       "1  ধূসর দাড়িওয়ালা একটি লোক জানালার কাছে বসে আছেন।  \n",
       "2         একটি কুকুর সমুদ্র তীরে পানির মধ্যে হাঁটছে  \n",
       "3                   দুজন বাইক চালক প্রতিযোগিতা করছে  \n",
       "4           দুইটি অভিন্ন কুকুর সতেজ তৃণভূমিতে আবদ্ধ  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>bn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>men with orange wristbands perform a dance .</td>\n",
       "      <td>কমলা রিস্টব্যান্ড পড়া লোক নাচছে ।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a man with a grey beard is sitting by a window .</td>\n",
       "      <td>ধূসর দাড়িওয়ালা একটি লোক জানালার কাছে বসে আছেন।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a dog walking through the water at the ocean .</td>\n",
       "      <td>একটি কুকুর সমুদ্র তীরে পানির মধ্যে হাঁটছে</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a bike racer in a red jersey is pursued by ano...</td>\n",
       "      <td>দুজন বাইক চালক প্রতিযোগিতা করছে</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>two identical dogs bound across a lush green m...</td>\n",
       "      <td>দুইটি অভিন্ন কুকুর সতেজ তৃণভূমিতে আবদ্ধ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T14:08:52.331875Z",
     "start_time": "2025-10-27T14:08:52.330238Z"
    }
   },
   "cell_type": "code",
   "source": [
    "''' Device Check '''\n",
    "Device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {Device}')"
   ],
   "id": "c5cd2fd182048880",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T14:08:52.435268Z",
     "start_time": "2025-10-27T14:08:52.433677Z"
    }
   },
   "cell_type": "code",
   "source": [
    "''' Pretrained Model '''\n",
    "Fine_Tune_Model_name = \"shhossain/opus-mt-en-to-bn\"\n"
   ],
   "id": "ca10a65987cf5f5c",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T14:08:55.914482Z",
     "start_time": "2025-10-27T14:08:52.453645Z"
    }
   },
   "cell_type": "code",
   "source": [
    "''' Tokenizer and Model '''\n",
    "Tokenizer = AutoTokenizer.from_pretrained(Fine_Tune_Model_name)\n",
    "Fine_Tune_Model = AutoModelForSeq2SeqLM.from_pretrained(Fine_Tune_Model_name)"
   ],
   "id": "f842cc5fc1178d1c",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### **Data(MT Part-1)**",
   "id": "811f8779f99f462e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T14:08:55.939661Z",
     "start_time": "2025-10-27T14:08:55.936420Z"
    }
   },
   "cell_type": "code",
   "source": [
    "''' Dataset Class '''\n",
    "class MTDataset(Dataset):\n",
    "    # Read csv file using pandas\n",
    "    def __init__(self, data_path):\n",
    "        super().__init__()\n",
    "        self.data = pd.read_csv(data_path)\n",
    "    # Find Dataset Length\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    # Ready single example\n",
    "    def __getitem__(self, item):\n",
    "        # English\n",
    "        source_te = str(self.data.iloc[item]['en'])\n",
    "        # Bangla\n",
    "        target_te = str(self.data.iloc[item]['bn'])\n",
    "\n",
    "        # All Token size must be match\n",
    "        source_encoder = Tokenizer(\n",
    "            source_te,\n",
    "            max_length=256,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        target_encoder = Tokenizer(\n",
    "            target_te,\n",
    "            max_length=256,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        # return outputs\n",
    "        return {\n",
    "            'source_encoder_input_ids': source_encoder['input_ids'].squeeze(),\n",
    "            'source_encoder_attention_mask': source_encoder['attention_mask'].squeeze(),\n",
    "            'target_encoder_input_ids': target_encoder['input_ids'].squeeze(),\n",
    "            'target_encoder_attention_mask': target_encoder['attention_mask'].squeeze(),\n",
    "        }\n"
   ],
   "id": "2a44c8a2d44cf502",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T14:08:55.946969Z",
     "start_time": "2025-10-27T14:08:55.944149Z"
    }
   },
   "cell_type": "code",
   "source": [
    "''' DataModule Class '''\n",
    "class MTDataModule(pytorch_lightning.LightningDataModule):\n",
    "    # Load Dataset using pandas\n",
    "    def __init__(self, train_csv, test_csv, val_csv, batch_size):\n",
    "        super().__init__()\n",
    "        self.train = train_csv\n",
    "        self.test = test_csv\n",
    "        self.val = val_csv\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    # Dataset\n",
    "    def setup(self, stage = None):\n",
    "        self.train_dataset = MTDataset(self.train)\n",
    "        self.test_dataset = MTDataset(self.test)\n",
    "        self.val_dataset = MTDataset(self.val)\n",
    "\n",
    "    # train Dataloader\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "        )\n",
    "    # validation Dataloader\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "             self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "        )\n",
    "    # Test Dataloader\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "        )\n"
   ],
   "id": "ff3722fdcedea124",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T14:08:55.952542Z",
     "start_time": "2025-10-27T14:08:55.950939Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Data_Module = MTDataModule(\n",
    "    train_csv=train_path,\n",
    "    test_csv=test_path,\n",
    "    val_csv=validation_path,\n",
    "    batch_size=32,\n",
    ")"
   ],
   "id": "dd34ee0c27ea6432",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### **Model (Fine-Tune) (MT Part-2)**",
   "id": "5c558db923ed974"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T14:08:55.960135Z",
     "start_time": "2025-10-27T14:08:55.955920Z"
    }
   },
   "cell_type": "code",
   "source": [
    "''' Model '''\n",
    "class MTModel(pytorch_lightning.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Load Model\n",
    "        self.model = AutoModelForSeq2SeqLM.from_pretrained(Fine_Tune_Model_name)\n",
    "        # Load Tokenizer\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(Fine_Tune_Model_name)\n",
    "        # learning Rate\n",
    "        self.lr = 0.001\n",
    "        # loss func\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        # Bleuscore\n",
    "        self.blue = BLEUScore()\n",
    "\n",
    "    def forward(self,sour_input_ids, sour_attention_mask, tar_input_ids, tar_attention_mask):\n",
    "        outputs = self.model(\n",
    "            input_ids=sour_input_ids,\n",
    "            attention_mask=sour_attention_mask,\n",
    "            decoder_input_ids=tar_input_ids[:, :-1],\n",
    "            decoder_attention_mask=tar_attention_mask[:, :-1],\n",
    "        )\n",
    "        return outputs\n",
    "\n",
    "    # Training Step\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self.Compute_Loss(batch, batch_idx, 'train')\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    # Validation Step\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss = self.Compute_Loss(batch, batch_idx, 'val')\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    # Test Step\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss = self.Compute_Loss(batch, batch_idx, 'test')\n",
    "        self.log('test_loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    # Gradient Descent\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        scheduler = torch.optim.lr_schedule.CosineAnnealingLR(\n",
    "            optimizer,\n",
    "            T_max=10,\n",
    "        )\n",
    "        return {'optimizer': optimizer, 'lr_scheduler': scheduler}\n",
    "\n",
    "    # Compute loss\n",
    "    def Compute_Loss(self, batch, batch_idx, stage):\n",
    "        source_input_ids = batch['source_encoder_input_ids']\n",
    "        source_attention_mask = batch['source_attention_mask']\n",
    "        target_input_ids = batch['target_encoder_input_ids']\n",
    "        target_attention_mask = batch['target_attention_mask']\n",
    "\n",
    "        outputs = self.forward(\n",
    "            source_input_ids,\n",
    "            source_attention_mask,\n",
    "            target_input_ids,\n",
    "            target_attention_mask\n",
    "        )\n",
    "\n",
    "        logits = outputs.logits\n",
    "        loss = self.criterion(\n",
    "            logits.view(-1, logits.size(-1)),\n",
    "            target_input_ids[:,1:].contiguous().view(-1)\n",
    "        )\n",
    "\n",
    "        if stage == 'test' or 'val':\n",
    "            preds = torch.argmax(logits, dim=-1)\n",
    "            pred_text = self.tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "            target_text = self.tokenizer.batch_decode(target_input_ids, skip_special_tokens=True)\n",
    "            bleu_score = self.blue(pred_text, [[target] for target in target_text])\n",
    "            self.log(f'{stage}_bleu_score', bleu_score, prog_bar=True)\n",
    "\n",
    "        return loss"
   ],
   "id": "c763111e937d392a",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T14:09:40.546955Z",
     "start_time": "2025-10-27T14:09:37.275202Z"
    }
   },
   "cell_type": "code",
   "source": "Model = MTModel()",
   "id": "90ef93adea10cbc7",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### **Train (MT Part-3)**",
   "id": "9968ebc57696ca3e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T14:14:34.564463Z",
     "start_time": "2025-10-27T14:14:34.500753Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Training_Model = pytorch_lightning.Trainer(\n",
    "    max_epochs=10,\n",
    "    accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n",
    "    devices=1,\n",
    "    precision=16,\n",
    "    log_every_n_steps=10,\n",
    "    val_check_interval=0.25,\n",
    "\n",
    ")"
   ],
   "id": "a8c8c1e85ca167e8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/lightning_fabric/connector.py:571: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:508: You passed `Trainer(accelerator='cpu', precision='16-mixed')` but AMP with fp16 is not supported on CPU. Using `precision='bf16-mixed'` instead.\n",
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pytorch_lightning/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n"
     ]
    }
   ],
   "execution_count": 41
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
