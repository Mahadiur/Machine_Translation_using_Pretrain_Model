{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": "### **Machine Translation using Pretrain Model**",
   "id": "8ba0d0d2b0b3fcb8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T14:08:52.226974Z",
     "start_time": "2025-10-27T14:08:52.224513Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pytorch_lightning.utilities.types import EVAL_DATALOADERS\n",
    "\n",
    "''' Import all important Library '''\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import pytorch_lightning\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch.nn as nn\n",
    "from torchmetrics.text import  BLEUScore"
   ],
   "id": "1ebf8cc152cc8749",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T14:08:52.236664Z",
     "start_time": "2025-10-27T14:08:52.234445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "''' Root and Dataset Path '''\n",
    "Root_dir = '/Users/mahadiur/Desktop/Bongodev MLops Projects/Machine Translation using Pretrain Model/Data'\n",
    "\n",
    "train_path = os.path.join(Root_dir, 'train.csv')\n",
    "test_path = os.path.join(Root_dir, 'test.csv')\n",
    "validation_path = os.path.join(Root_dir, 'val.csv')\n"
   ],
   "id": "ff3d084dfdf4301e",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T14:08:52.311500Z",
     "start_time": "2025-10-27T14:08:52.243562Z"
    }
   },
   "cell_type": "code",
   "source": [
    "''' Load Dataset '''\n",
    "train_dataset = pd.read_csv(train_path)\n",
    "test_dataset = pd.read_csv(test_path)\n",
    "validation_dataset = pd.read_csv(validation_path)\n",
    "\n",
    "train_dataset.head()"
   ],
   "id": "aafc870bdd777f38",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                  en  \\\n",
       "0       men with orange wristbands perform a dance .   \n",
       "1   a man with a grey beard is sitting by a window .   \n",
       "2     a dog walking through the water at the ocean .   \n",
       "3  a bike racer in a red jersey is pursued by ano...   \n",
       "4  two identical dogs bound across a lush green m...   \n",
       "\n",
       "                                                 bn  \n",
       "0                ‡¶ï‡¶Æ‡¶≤‡¶æ ‡¶∞‡¶ø‡¶∏‡ßç‡¶ü‡¶¨‡ßç‡¶Ø‡¶æ‡¶®‡ßç‡¶° ‡¶™‡¶°‡¶º‡¶æ ‡¶≤‡ßã‡¶ï ‡¶®‡¶æ‡¶ö‡¶õ‡ßá ‡•§  \n",
       "1  ‡¶ß‡ßÇ‡¶∏‡¶∞ ‡¶¶‡¶æ‡¶°‡¶º‡¶ø‡¶ì‡¶Ø‡¶º‡¶æ‡¶≤‡¶æ ‡¶è‡¶ï‡¶ü‡¶ø ‡¶≤‡ßã‡¶ï ‡¶ú‡¶æ‡¶®‡¶æ‡¶≤‡¶æ‡¶∞ ‡¶ï‡¶æ‡¶õ‡ßá ‡¶¨‡¶∏‡ßá ‡¶Ü‡¶õ‡ßá‡¶®‡•§  \n",
       "2         ‡¶è‡¶ï‡¶ü‡¶ø ‡¶ï‡ßÅ‡¶ï‡ßÅ‡¶∞ ‡¶∏‡¶Æ‡ßÅ‡¶¶‡ßç‡¶∞ ‡¶§‡ßÄ‡¶∞‡ßá ‡¶™‡¶æ‡¶®‡¶ø‡¶∞ ‡¶Æ‡¶ß‡ßç‡¶Ø‡ßá ‡¶π‡¶æ‡¶Å‡¶ü‡¶õ‡ßá  \n",
       "3                   ‡¶¶‡ßÅ‡¶ú‡¶® ‡¶¨‡¶æ‡¶á‡¶ï ‡¶ö‡¶æ‡¶≤‡¶ï ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶Ø‡ßã‡¶ó‡¶ø‡¶§‡¶æ ‡¶ï‡¶∞‡¶õ‡ßá  \n",
       "4           ‡¶¶‡ßÅ‡¶á‡¶ü‡¶ø ‡¶Ö‡¶≠‡¶ø‡¶®‡ßç‡¶® ‡¶ï‡ßÅ‡¶ï‡ßÅ‡¶∞ ‡¶∏‡¶§‡ßá‡¶ú ‡¶§‡ßÉ‡¶£‡¶≠‡ßÇ‡¶Æ‡¶ø‡¶§‡ßá ‡¶Ü‡¶¨‡¶¶‡ßç‡¶ß  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>bn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>men with orange wristbands perform a dance .</td>\n",
       "      <td>‡¶ï‡¶Æ‡¶≤‡¶æ ‡¶∞‡¶ø‡¶∏‡ßç‡¶ü‡¶¨‡ßç‡¶Ø‡¶æ‡¶®‡ßç‡¶° ‡¶™‡¶°‡¶º‡¶æ ‡¶≤‡ßã‡¶ï ‡¶®‡¶æ‡¶ö‡¶õ‡ßá ‡•§</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a man with a grey beard is sitting by a window .</td>\n",
       "      <td>‡¶ß‡ßÇ‡¶∏‡¶∞ ‡¶¶‡¶æ‡¶°‡¶º‡¶ø‡¶ì‡¶Ø‡¶º‡¶æ‡¶≤‡¶æ ‡¶è‡¶ï‡¶ü‡¶ø ‡¶≤‡ßã‡¶ï ‡¶ú‡¶æ‡¶®‡¶æ‡¶≤‡¶æ‡¶∞ ‡¶ï‡¶æ‡¶õ‡ßá ‡¶¨‡¶∏‡ßá ‡¶Ü‡¶õ‡ßá‡¶®‡•§</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a dog walking through the water at the ocean .</td>\n",
       "      <td>‡¶è‡¶ï‡¶ü‡¶ø ‡¶ï‡ßÅ‡¶ï‡ßÅ‡¶∞ ‡¶∏‡¶Æ‡ßÅ‡¶¶‡ßç‡¶∞ ‡¶§‡ßÄ‡¶∞‡ßá ‡¶™‡¶æ‡¶®‡¶ø‡¶∞ ‡¶Æ‡¶ß‡ßç‡¶Ø‡ßá ‡¶π‡¶æ‡¶Å‡¶ü‡¶õ‡ßá</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a bike racer in a red jersey is pursued by ano...</td>\n",
       "      <td>‡¶¶‡ßÅ‡¶ú‡¶® ‡¶¨‡¶æ‡¶á‡¶ï ‡¶ö‡¶æ‡¶≤‡¶ï ‡¶™‡ßç‡¶∞‡¶§‡¶ø‡¶Ø‡ßã‡¶ó‡¶ø‡¶§‡¶æ ‡¶ï‡¶∞‡¶õ‡ßá</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>two identical dogs bound across a lush green m...</td>\n",
       "      <td>‡¶¶‡ßÅ‡¶á‡¶ü‡¶ø ‡¶Ö‡¶≠‡¶ø‡¶®‡ßç‡¶® ‡¶ï‡ßÅ‡¶ï‡ßÅ‡¶∞ ‡¶∏‡¶§‡ßá‡¶ú ‡¶§‡ßÉ‡¶£‡¶≠‡ßÇ‡¶Æ‡¶ø‡¶§‡ßá ‡¶Ü‡¶¨‡¶¶‡ßç‡¶ß</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T14:08:52.331875Z",
     "start_time": "2025-10-27T14:08:52.330238Z"
    }
   },
   "cell_type": "code",
   "source": [
    "''' Device Check '''\n",
    "Device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {Device}')"
   ],
   "id": "c5cd2fd182048880",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T14:08:52.435268Z",
     "start_time": "2025-10-27T14:08:52.433677Z"
    }
   },
   "cell_type": "code",
   "source": [
    "''' Pretrained Model '''\n",
    "Fine_Tune_Model_name = \"shhossain/opus-mt-en-to-bn\"\n"
   ],
   "id": "ca10a65987cf5f5c",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T14:08:55.914482Z",
     "start_time": "2025-10-27T14:08:52.453645Z"
    }
   },
   "cell_type": "code",
   "source": [
    "''' Tokenizer and Model '''\n",
    "Tokenizer = AutoTokenizer.from_pretrained(Fine_Tune_Model_name)\n",
    "Fine_Tune_Model = AutoModelForSeq2SeqLM.from_pretrained(Fine_Tune_Model_name)"
   ],
   "id": "f842cc5fc1178d1c",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### **Data(MT Part-1)**",
   "id": "811f8779f99f462e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T14:08:55.939661Z",
     "start_time": "2025-10-27T14:08:55.936420Z"
    }
   },
   "cell_type": "code",
   "source": [
    "''' Dataset Class '''\n",
    "class MTDataset(Dataset):\n",
    "    # Read csv file using pandas\n",
    "    def __init__(self, data_path):\n",
    "        super().__init__()\n",
    "        self.data = pd.read_csv(data_path)\n",
    "    # Find Dataset Length\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    # Ready single example\n",
    "    def __getitem__(self, item):\n",
    "        # English\n",
    "        source_te = str(self.data.iloc[item]['en'])\n",
    "        # Bangla\n",
    "        target_te = str(self.data.iloc[item]['bn'])\n",
    "\n",
    "        # All Token size must be match\n",
    "        source_encoder = Tokenizer(\n",
    "            source_te,\n",
    "            max_length=256,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        target_encoder = Tokenizer(\n",
    "            target_te,\n",
    "            max_length=256,\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        # return outputs\n",
    "        return {\n",
    "            'source_encoder_input_ids': source_encoder['input_ids'].squeeze(),\n",
    "            'source_encoder_attention_mask': source_encoder['attention_mask'].squeeze(),\n",
    "            'target_encoder_input_ids': target_encoder['input_ids'].squeeze(),\n",
    "            'target_encoder_attention_mask': target_encoder['attention_mask'].squeeze(),\n",
    "        }\n"
   ],
   "id": "2a44c8a2d44cf502",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T14:08:55.946969Z",
     "start_time": "2025-10-27T14:08:55.944149Z"
    }
   },
   "cell_type": "code",
   "source": [
    "''' DataModule Class '''\n",
    "class MTDataModule(pytorch_lightning.LightningDataModule):\n",
    "    # Load Dataset using pandas\n",
    "    def __init__(self, train_csv, test_csv, val_csv, batch_size):\n",
    "        super().__init__()\n",
    "        self.train = train_csv\n",
    "        self.test = test_csv\n",
    "        self.val = val_csv\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    # Dataset\n",
    "    def setup(self, stage = None):\n",
    "        self.train_dataset = MTDataset(self.train)\n",
    "        self.test_dataset = MTDataset(self.test)\n",
    "        self.val_dataset = MTDataset(self.val)\n",
    "\n",
    "    # train Dataloader\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "        )\n",
    "    # validation Dataloader\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "             self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "        )\n",
    "    # Test Dataloader\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "        )\n"
   ],
   "id": "ff3722fdcedea124",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T14:08:55.952542Z",
     "start_time": "2025-10-27T14:08:55.950939Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Data_Module = MTDataModule(\n",
    "    train_csv=train_path,\n",
    "    test_csv=test_path,\n",
    "    val_csv=validation_path,\n",
    "    batch_size=32,\n",
    ")"
   ],
   "id": "dd34ee0c27ea6432",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### **Model (Fine-Tune) (MT Part-2)**",
   "id": "5c558db923ed974"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T14:08:55.960135Z",
     "start_time": "2025-10-27T14:08:55.955920Z"
    }
   },
   "cell_type": "code",
   "source": [
    "''' Model '''\n",
    "class MTModel(pytorch_lightning.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Load Model\n",
    "        self.model = AutoModelForSeq2SeqLM.from_pretrained(Fine_Tune_Model_name)\n",
    "        # Load Tokenizer\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(Fine_Tune_Model_name)\n",
    "        # learning Rate\n",
    "        self.lr = 0.001\n",
    "        # loss func\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        # Bleuscore\n",
    "        self.blue = BLEUScore()\n",
    "\n",
    "    def forward(self,sour_input_ids, sour_attention_mask, tar_input_ids, tar_attention_mask):\n",
    "        outputs = self.model(\n",
    "            input_ids=sour_input_ids,\n",
    "            attention_mask=sour_attention_mask,\n",
    "            decoder_input_ids=tar_input_ids[:, :-1],\n",
    "            decoder_attention_mask=tar_attention_mask[:, :-1],\n",
    "        )\n",
    "        return outputs\n",
    "\n",
    "    # Training Step\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self.Compute_Loss(batch, batch_idx, 'train')\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    # Validation Step\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss = self.Compute_Loss(batch, batch_idx, 'val')\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    # Test Step\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss = self.Compute_Loss(batch, batch_idx, 'test')\n",
    "        self.log('test_loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    # Gradient Descent\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        scheduler = torch.optim.lr_schedule.CosineAnnealingLR(\n",
    "            optimizer,\n",
    "            T_max=10,\n",
    "        )\n",
    "        return {'optimizer': optimizer, 'lr_scheduler': scheduler}\n",
    "\n",
    "    # Compute loss\n",
    "    def Compute_Loss(self, batch, batch_idx, stage):\n",
    "        source_input_ids = batch['source_encoder_input_ids']\n",
    "        source_attention_mask = batch['source_attention_mask']\n",
    "        target_input_ids = batch['target_encoder_input_ids']\n",
    "        target_attention_mask = batch['target_attention_mask']\n",
    "\n",
    "        outputs = self.forward(\n",
    "            source_input_ids,\n",
    "            source_attention_mask,\n",
    "            target_input_ids,\n",
    "            target_attention_mask\n",
    "        )\n",
    "\n",
    "        logits = outputs.logits\n",
    "        loss = self.criterion(\n",
    "            logits.view(-1, logits.size(-1)),\n",
    "            target_input_ids[:,1:].contiguous().view(-1)\n",
    "        )\n",
    "\n",
    "        if stage == 'test' or 'val':\n",
    "            preds = torch.argmax(logits, dim=-1)\n",
    "            pred_text = self.tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "            target_text = self.tokenizer.batch_decode(target_input_ids, skip_special_tokens=True)\n",
    "            bleu_score = self.blue(pred_text, [[target] for target in target_text])\n",
    "            self.log(f'{stage}_bleu_score', bleu_score, prog_bar=True)\n",
    "\n",
    "        return loss"
   ],
   "id": "c763111e937d392a",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T14:09:40.546955Z",
     "start_time": "2025-10-27T14:09:37.275202Z"
    }
   },
   "cell_type": "code",
   "source": "Model = MTModel()",
   "id": "90ef93adea10cbc7",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### **Train (MT Part-3)**",
   "id": "9968ebc57696ca3e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T14:14:34.564463Z",
     "start_time": "2025-10-27T14:14:34.500753Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Training_Model = pytorch_lightning.Trainer(\n",
    "    max_epochs=10,\n",
    "    accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n",
    "    devices=1,\n",
    "    precision=16,\n",
    "    log_every_n_steps=10,\n",
    "    val_check_interval=0.25,\n",
    "\n",
    ")"
   ],
   "id": "a8c8c1e85ca167e8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/lightning_fabric/connector.py:571: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:508: You passed `Trainer(accelerator='cpu', precision='16-mixed')` but AMP with fp16 is not supported on CPU. Using `precision='bf16-mixed'` instead.\n",
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "üí° Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pytorch_lightning/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n"
     ]
    }
   ],
   "execution_count": 41
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
